{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ad_predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YHj-G_ISl8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "920d03df-f73f-4234-e6a5-7484d10e0618"
      },
      "source": [
        "!unzip /content/data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/data.zip\n",
            "   creating: data/\n",
            "  inflating: data/.DS_Store          \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "   creating: data/AD/\n",
            "  inflating: data/AD/wwmAD_057_S_0474_64218.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_0889_83484.nii  \n",
            "  inflating: data/AD/wwmAD_027_S_0404_82214.nii  \n",
            "  inflating: data/AD/wwmAD_116_S_0392_86146.nii  \n",
            "  inflating: data/AD/wwmAD_067_S_0029_119181.nii  \n",
            "  inflating: data/AD/wwmAD_126_S_1221_91967.nii  \n",
            "  inflating: data/AD/wwmAD_073_S_0565_119234.nii  \n",
            "  inflating: data/AD/wwmAD_002_S_0938_118685.nii  \n",
            "  inflating: data/AD/wwmAD_137_S_0796_91210.nii  \n",
            "  inflating: data/AD/wwmAD_136_S_0299_119726.nii  \n",
            "  inflating: data/AD/wwmAD_123_S_0091_119290.nii  \n",
            "  inflating: data/AD/wwmAD_036_S_0577_72195.nii  \n",
            "  inflating: data/AD/wwmAD_027_S_0850_94797.nii  \n",
            "  inflating: data/AD/wwmAD_062_S_0793_82351.nii  \n",
            "  inflating: data/AD/wwmAD_021_S_0753_78869.nii  \n",
            "  inflating: data/AD/wwmAD_021_S_0343_85699.nii  \n",
            "  inflating: data/AD/wwmAD_126_S_0784_82633.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_1281_102012.nii  \n",
            "  inflating: data/AD/wwmAD_023_S_0916_118884.nii  \n",
            "  inflating: data/AD/wwmAD_114_S_0374_68600.nii  \n",
            "  inflating: data/AD/wwmAD_109_S_1157_128789.nii  \n",
            "  inflating: data/AD/wwmAD_012_S_0803_118747.nii  \n",
            "  inflating: data/AD/wwmAD_032_S_0400_119089.nii  \n",
            "  inflating: data/AD/wwmAD_136_S_0300_119728.nii  \n",
            "  inflating: data/AD/wwmAD_005_S_0221_102054.nii  \n",
            "  inflating: data/AD/wwmAD_027_S_1254_91684.nii  \n",
            "  inflating: data/AD/wwmAD_010_S_0829_118707.nii  \n",
            "  inflating: data/AD/wwmAD_062_S_0730_85959.nii  \n",
            "  inflating: data/AD/wwmAD_023_S_0083_118877.nii  \n",
            "  inflating: data/AD/wwmAD_005_S_1341_103336.nii  \n",
            "  inflating: data/AD/wwmAD_098_S_0149_89454.nii  \n",
            "  inflating: data/AD/wwmAD_067_S_0076_119191.nii  \n",
            "  inflating: data/AD/wwmAD_012_S_0689_118754.nii  \n",
            "  inflating: data/AD/wwmAD_032_S_0147_124906.nii  \n",
            "  inflating: data/AD/wwmAD_027_S_1081_91679.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_1285_101710.nii  \n",
            "  inflating: data/AD/wwmAD_057_S_1371_109122.nii  \n",
            "  inflating: data/AD/wwmAD_024_S_1171_91640.nii  \n",
            "  inflating: data/AD/wwmAD_057_S_1379_109131.nii  \n",
            "  inflating: data/AD/wwmAD_062_S_0690_73145.nii  \n",
            "  inflating: data/AD/wwmAD_041_S_1368_102387.nii  \n",
            "  inflating: data/AD/wwmAD_016_S_0991_88024.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_1283_101691.nii  \n",
            "  inflating: data/AD/wwmAD_099_S_0470_88563.nii  \n",
            "  inflating: data/AD/wwmAD_127_S_0431_80737.nii  \n",
            "  inflating: data/AD/wwmAD_013_S_1205_91450.nii  \n",
            "  inflating: data/AD/wwmAD_023_S_0139_118978.nii  \n",
            "  inflating: data/AD/wwmAD_126_S_0891_80899.nii  \n",
            "  inflating: data/AD/wwmAD_133_S_1170_119656.nii  \n",
            "  inflating: data/AD/wwmAD_062_S_0535_72297.nii  \n",
            "  inflating: data/AD/wwmAD_127_S_1382_105481.nii  \n",
            "  inflating: data/AD/wwmAD_123_S_0162_119327.nii  \n",
            "  inflating: data/AD/wwmAD_114_S_0979_92217.nii  \n",
            "  inflating: data/AD/wwmAD_021_S_1109_91483.nii  \n",
            "  inflating: data/AD/wwmAD_022_S_0129_59493.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_0739_119135.nii  \n",
            "  inflating: data/AD/wwmAD_131_S_0497_71669.nii  \n",
            "  inflating: data/AD/wwmAD_051_S_1296_97143.nii  \n",
            "  inflating: data/AD/wwmAD_007_S_1339_104363.nii  \n",
            "  inflating: data/AD/wwmAD_023_S_0084_118993.nii  \n",
            "  inflating: data/AD/wwmAD_010_S_0786_118990.nii  \n",
            "  inflating: data/AD/wwmAD_029_S_1056_92182.nii  \n",
            "  inflating: data/AD/wwmAD_002_S_1018_87204.nii  \n",
            "  inflating: data/AD/wwmAD_011_S_0003_35576.nii  \n",
            "  inflating: data/AD/wwmAD_137_S_0366_66206.nii  \n",
            "  inflating: data/AD/wwmAD_068_S_0109_132912.nii  \n",
            "  inflating: data/AD/wwmAD_035_S_0341_68504.nii  \n",
            "  inflating: data/AD/wwmAD_057_S_1373_103707.nii  \n",
            "  inflating: data/AD/wwmAD_136_S_0426_119730.nii  \n",
            "  inflating: data/AD/wwmAD_131_S_0457_92406.nii  \n",
            "  inflating: data/AD/wwmAD_007_S_0316_74627.nii  \n",
            "  inflating: data/AD/wwmAD_014_S_0328_90019.nii  \n",
            "  inflating: data/AD/wwmAD_137_S_1041_86630.nii  \n",
            "  inflating: data/AD/wwmAD_036_S_0759_82336.nii  \n",
            "  inflating: data/AD/wwmAD_018_S_0286_118788.nii  \n",
            "  inflating: data/AD/wwmAD_006_S_0547_78722.nii  \n",
            "  inflating: data/AD/wwmAD_099_S_0372_65451.nii  \n",
            "  inflating: data/AD/wwmAD_036_S_0760_79913.nii  \n",
            "  inflating: data/AD/wwmAD_094_S_1164_121632.nii  \n",
            "  inflating: data/AD/wwmAD_018_S_0335_119801.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_0733_119132.nii  \n",
            "  inflating: data/AD/wwmAD_023_S_1262_118923.nii  \n",
            "  inflating: data/AD/wwmAD_116_S_0487_86136.nii  \n",
            "  inflating: data/AD/wwmAD_031_S_0554_92187.nii  \n",
            "  inflating: data/AD/wwmAD_027_S_1082_65365.nii  \n",
            "  inflating: data/AD/wwmAD_116_S_0370_87744.nii  \n",
            "  inflating: data/AD/wwmAD_127_S_0754_80908.nii  \n",
            "  inflating: data/AD/wwmAD_005_S_0814_78700.nii  \n",
            "  inflating: data/AD/wwmAD_011_S_0053_66945.nii  \n",
            "  inflating: data/AD/wwmAD_024_S_1307_96266.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_0724_119128.nii  \n",
            "  inflating: data/AD/wwmAD_011_S_0183_87324.nii  \n",
            "  inflating: data/AD/wwmAD_011_S_0010_94368.nii  \n",
            "  inflating: data/AD/wwmAD_123_S_0094_119306.nii  \n",
            "  inflating: data/AD/wwmAD_127_S_0844_82642.nii  \n",
            "  inflating: data/AD/wwmAD_027_S_1385_101549.nii  \n",
            "  inflating: data/AD/wwmAD_002_S_0619_118678.nii  \n",
            "  inflating: data/AD/wwmAD_099_S_1144_87274.nii  \n",
            "  inflating: data/AD/wwmAD_033_S_1308_102378.nii  \n",
            "   creating: data/normal/\n",
            "  inflating: data/normal/wwmNL_041_S_0262_124897.nii  \n",
            "  inflating: data/normal/wwmNL_098_S_0171_89468.nii  \n",
            "  inflating: data/normal/wwmNL_137_S_0301_89089.nii  \n",
            "  inflating: data/normal/wwmNL_007_S_0068_118699.nii  \n",
            "  inflating: data/normal/wwmNL_033_S_0741_119136.nii  \n",
            "  inflating: data/normal/wwmNL_057_S_0779_80629.nii  \n",
            "  inflating: data/normal/wwmNL_116_S_1232_91905.nii  \n",
            "  inflating: data/normal/wwmNL_029_S_0866_82274.nii  \n",
            "  inflating: data/normal/wwmNL_068_S_0473_140334.nii  \n",
            "  inflating: data/normal/wwmNL_033_S_1098_86698.nii  \n",
            "  inflating: data/normal/wwmNL_010_S_0419_118701.nii  \n",
            "  inflating: data/normal/wwmNL_002_S_0413_118695.nii  \n",
            "  inflating: data/normal/wwmNL_033_S_1016_86245.nii  \n",
            "  inflating: data/normal/wwmNL_041_S_0898_87256.nii  \n",
            "  inflating: data/normal/wwmNL_057_S_0643_83126.nii  \n",
            "  inflating: data/normal/wwmNL_114_S_0601_68153.nii  \n",
            "  inflating: data/normal/wwmNL_094_S_0526_80713.nii  \n",
            "  inflating: data/normal/wwmNL_036_S_1023_98811.nii  \n",
            "  inflating: data/normal/wwmNL_114_S_0166_68134.nii  \n",
            "  inflating: data/normal/wwmNL_123_S_0298_119330.nii  \n",
            "  inflating: data/normal/wwmNL_011_S_0016_32306.nii  \n",
            "  inflating: data/normal/wwmNL_032_S_1169_119119.nii  \n",
            "  inflating: data/normal/wwmNL_016_S_0359_96221.nii  \n",
            "  inflating: data/normal/wwmNL_036_S_0672_73118.nii  \n",
            "  inflating: data/normal/wwmNL_131_S_0123_70876.nii  \n",
            "  inflating: data/normal/wwmNL_057_S_0818_121435.nii  \n",
            "  inflating: data/normal/wwmNL_127_S_0259_75336.nii  \n",
            "  inflating: data/normal/wwmNL_002_S_0685_118680.nii  \n",
            "  inflating: data/normal/wwmNL_098_S_0896_80437.nii  \n",
            "  inflating: data/normal/wwmNL_024_S_1063_83398.nii  \n",
            "  inflating: data/normal/wwmNL_068_S_0210_132914.nii  \n",
            "  inflating: data/normal/wwmNL_027_S_0403_70692.nii  \n",
            "  inflating: data/normal/wwmNL_073_S_0089_119228.nii  \n",
            "  inflating: data/normal/wwmNL_136_S_0086_119678.nii  \n",
            "  inflating: data/normal/wwmNL_013_S_0502_75291.nii  \n",
            "  inflating: data/normal/wwmNL_037_S_0454_90558.nii  \n",
            "  inflating: data/normal/wwmNL_035_S_0048_83503.nii  \n",
            "  inflating: data/normal/wwmNL_023_S_0031_118843.nii  \n",
            "  inflating: data/normal/wwmNL_073_S_0386_119231.nii  \n",
            "  inflating: data/normal/wwmNL_099_S_0040_47884.nii  \n",
            "  inflating: data/normal/wwmNL_067_S_0257_119198.nii  \n",
            "  inflating: data/normal/wwmNL_005_S_0610_74582.nii  \n",
            "  inflating: data/normal/wwmNL_131_S_0441_86106.nii  \n",
            "  inflating: data/normal/wwmNL_052_S_1250_83117.nii  \n",
            "  inflating: data/normal/wwmNL_133_S_0433_119483.nii  \n",
            "  inflating: data/normal/wwmNL_099_S_0533_68788.nii  \n",
            "  inflating: data/normal/wwmNL_007_S_1206_96025.nii  \n",
            "  inflating: data/normal/wwmNL_023_S_1190_118919.nii  \n",
            "  inflating: data/normal/wwmNL_021_S_0159_67958.nii  \n",
            "  inflating: data/normal/wwmNL_002_S_0295_118692.nii  \n",
            "  inflating: data/normal/wwmNL_127_S_0622_86188.nii  \n",
            "  inflating: data/normal/wwmNL_022_S_0014_64654.nii  \n",
            "  inflating: data/normal/wwmNL_011_S_0021_32332.nii  \n",
            "  inflating: data/normal/wwmNL_023_S_0963_118905.nii  \n",
            "  inflating: data/normal/wwmNL_129_S_0778_102525.nii  \n",
            "  inflating: data/normal/wwmNL_023_S_0081_118873.nii  \n",
            "  inflating: data/normal/wwmNL_027_S_0074_119067.nii  \n",
            "  inflating: data/normal/wwmNL_116_S_1249_99187.nii  \n",
            "  inflating: data/normal/wwmNL_005_S_0223_102045.nii  \n",
            "  inflating: data/normal/wwmNL_116_S_0657_82619.nii  \n",
            "  inflating: data/normal/wwmNL_041_S_0125_67522.nii  \n",
            "  inflating: data/normal/wwmNL_127_S_0260_86120.nii  \n",
            "  inflating: data/normal/wwmNL_031_S_0618_91766.nii  \n",
            "  inflating: data/normal/wwmNL_126_S_0680_48932.nii  \n",
            "  inflating: data/normal/wwmNL_027_S_0118_47149.nii  \n",
            "  inflating: data/normal/wwmNL_941_S_1194_103731.nii  \n",
            "  inflating: data/normal/wwmNL_022_S_0096_76622.nii  \n",
            "  inflating: data/normal/wwmNL_033_S_0516_119125.nii  \n",
            "  inflating: data/normal/wwmNL_016_S_0538_78823.nii  \n",
            "  inflating: data/normal/wwmNL_041_S_1002_87265.nii  \n",
            "  inflating: data/normal/wwmNL_136_S_0186_119716.nii  \n",
            "  inflating: data/normal/wwmNL_011_S_0005_32246.nii  \n",
            "  inflating: data/normal/wwmNL_012_S_1133_118758.nii  \n",
            "  inflating: data/normal/wwmNL_133_S_0488_319786.nii  \n",
            "  inflating: data/normal/wwmNL_037_S_0327_79742.nii  \n",
            "  inflating: data/normal/wwmNL_033_S_0923_82313.nii  \n",
            "  inflating: data/normal/wwmNL_014_S_0548_71412.nii  \n",
            "  inflating: data/normal/wwmNL_002_S_1280_138890.nii  \n",
            "  inflating: data/normal/wwmNL_029_S_0843_88417.nii  \n",
            "  inflating: data/normal/wwmNL_013_S_0575_78805.nii  \n",
            "  inflating: data/normal/wwmNL_023_S_0058_134207.nii  \n",
            "  inflating: data/normal/wwmNL_002_S_1261_109394.nii  \n",
            "  inflating: data/normal/wwmNL_029_S_0845_78903.nii  \n",
            "  inflating: data/normal/wwmNL_005_S_0602_67668.nii  \n",
            "  inflating: data/normal/wwmNL_137_S_0283_67275.nii  \n",
            "  inflating: data/normal/wwmNL_126_S_0605_80796.nii  \n",
            "  inflating: data/normal/wwmNL_029_S_0824_96284.nii  \n",
            "  inflating: data/normal/wwmNL_012_S_0637_118739.nii  \n",
            "  inflating: data/normal/wwmNL_099_S_0090_102436.nii  \n",
            "  inflating: data/normal/wwmNL_035_S_0156_79723.nii  \n",
            "  inflating: data/normal/wwmNL_052_S_0951_119138.nii  \n",
            "  inflating: data/normal/wwmNL_131_S_1301_102827.nii  \n",
            "  inflating: data/normal/wwmNL_941_S_1202_105437.nii  \n",
            "  inflating: data/normal/wwmNL_014_S_0520_78608.nii  \n",
            "  inflating: data/normal/wwmNL_094_S_1241_121579.nii  \n",
            "  inflating: data/normal/wwmNL_013_S_1035_83364.nii  \n",
            "  inflating: data/normal/wwmNL_094_S_1267_101747.nii  \n",
            "  inflating: data/normal/wwmNL_021_S_0984_88036.nii  \n",
            "  inflating: data/normal/wwmNL_051_S_1123_97134.nii  \n",
            "  inflating: data/normal/wwmNL_099_S_0534_65464.nii  \n",
            "  inflating: data/normal/wwmNL_022_S_0066_96110.nii  \n",
            "  inflating: data/normal/wwmNL_057_S_0934_80243.nii  \n",
            "  inflating: data/normal/wwmNL_098_S_0172_89481.nii  \n",
            "  inflating: data/normal/wwmNL_136_S_0196_119724.nii  \n",
            "  inflating: data/normal/wwmNL_035_S_0555_102770.nii  \n",
            "  inflating: data/normal/wwmNL_037_S_0303_88065.nii  \n",
            "  inflating: data/normal/wwmNL_021_S_0337_68006.nii  \n",
            "  inflating: data/normal/wwmNL_024_S_0985_81405.nii  \n",
            "  inflating: data/normal/wwmNL_137_S_0972_103629.nii  \n",
            "  inflating: data/normal/wwmNL_020_S_1288_78860.nii  \n",
            "  inflating: data/normal/wwmNL_014_S_0519_71402.nii  \n",
            "  inflating: data/normal/wwmNL_033_S_0734_119134.nii  \n",
            "  inflating: data/normal/wwmNL_137_S_0686_74550.nii  \n",
            "  inflating: data/normal/wwmNL_068_S_0127_132913.nii  \n",
            "  inflating: data/normal/wwmNL_014_S_0558_71434.nii  \n",
            "  inflating: data/normal/wwmNL_023_S_0061_119062.nii  \n",
            "  inflating: data/normal/wwmNL_020_S_0883_94854.nii  \n",
            "  inflating: data/normal/wwmNL_036_S_0813_79922.nii  \n",
            "  inflating: data/normal/wwmNL_005_S_0553_73520.nii  \n",
            "  inflating: data/normal/wwmNL_052_S_1251_97152.nii  \n",
            "  inflating: data/normal/wwmNL_022_S_0130_64663.nii  \n",
            "  inflating: data/normal/wwmNL_116_S_0648_72814.nii  \n",
            "  inflating: data/normal/wwmNL_137_S_0459_89096.nii  \n",
            "  inflating: data/normal/wwmNL_099_S_0352_67743.nii  \n",
            "  inflating: data/normal/wwmNL_033_S_0920_83076.nii  \n",
            "  inflating: data/normal/wwmNL_116_S_0382_86150.nii  \n",
            "  inflating: data/normal/wwmNL_027_S_0120_119070.nii  \n",
            "  inflating: data/normal/wwmNL_020_S_0899_124822.nii  \n",
            "  inflating: data/normal/wwmNL_007_S_1222_96047.nii  \n",
            "  inflating: data/normal/wwmNL_114_S_0416_94899.nii  \n",
            "  inflating: data/normal/wwmNL_094_S_0711_75651.nii  \n",
            "  inflating: data/normal/wwmNL_023_S_0926_118902.nii  \n",
            "  inflating: data/normal/wwmNL_114_S_0173_96321.nii  \n",
            "  inflating: data/normal/wwmNL_011_S_0023_65902.nii  \n",
            "  inflating: data/normal/wwmNL_136_S_0184_119713.nii  \n",
            "   creating: data/MCI/\n",
            "  inflating: data/MCI/wwmMCI_011_S_0861_78787.nii  \n",
            "  inflating: data/MCI/wwmMCI_012_S_0634_118751.nii  \n",
            "  inflating: data/MCI/wwmMCI_029_S_0878_90889.nii  \n",
            "  inflating: data/MCI/wwmMCI_033_S_0567_119126.nii  \n",
            "  inflating: data/MCI/wwmMCI_037_S_1078_88559.nii  \n",
            "  inflating: data/MCI/wwmMCI_014_S_0169_45726.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0388_118868.nii  \n",
            "  inflating: data/MCI/wwmMCI_029_S_1318_105915.nii  \n",
            "  inflating: data/MCI/wwmMCI_007_S_0128_121135.nii  \n",
            "  inflating: data/MCI/wwmMCI_035_S_0204_66608.nii  \n",
            "  inflating: data/MCI/wwmMCI_007_S_0101_118700.nii  \n",
            "  inflating: data/MCI/wwmMCI_002_S_1268_109403.nii  \n",
            "  inflating: data/MCI/wwmMCI_005_S_1224_104396.nii  \n",
            "  inflating: data/MCI/wwmMCI_052_S_1352_104380.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0604_119005.nii  \n",
            "  inflating: data/MCI/wwmMCI_037_S_0150_68534.nii  \n",
            "  inflating: data/MCI/wwmMCI_005_S_0324_86025.nii  \n",
            "  inflating: data/MCI/wwmMCI_127_S_1419_121684.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_1046_118910.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0443_79268.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_1414_121712.nii  \n",
            "  inflating: data/MCI/wwmMCI_011_S_0326_89390.nii  \n",
            "  inflating: data/MCI/wwmMCI_052_S_0671_71642.nii  \n",
            "  inflating: data/MCI/wwmMCI_037_S_0539_79792.nii  \n",
            "  inflating: data/MCI/wwmMCI_094_S_1188_91882.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_0408_92534.nii  \n",
            "  inflating: data/MCI/wwmMCI_033_S_0922_83085.nii  \n",
            "  inflating: data/MCI/wwmMCI_005_S_0546_75633.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_0644_68088.nii  \n",
            "  inflating: data/MCI/wwmMCI_035_S_0033_65833.nii  \n",
            "  inflating: data/MCI/wwmMCI_136_S_0429_66806.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0376_118976.nii  \n",
            "  inflating: data/MCI/wwmMCI_032_S_0214_119086.nii  \n",
            "  inflating: data/MCI/wwmMCI_029_S_0914_124879.nii  \n",
            "  inflating: data/MCI/wwmMCI_127_S_1140_94649.nii  \n",
            "  inflating: data/MCI/wwmMCI_016_S_0702_98747.nii  \n",
            "  inflating: data/MCI/wwmMCI_053_S_0389_119142.nii  \n",
            "  inflating: data/MCI/wwmMCI_057_S_1007_88443.nii  \n",
            "  inflating: data/MCI/wwmMCI_116_S_0834_92595.nii  \n",
            "  inflating: data/MCI/wwmMCI_033_S_0906_83498.nii  \n",
            "  inflating: data/MCI/wwmMCI_123_S_1300_119334.nii  \n",
            "  inflating: data/MCI/wwmMCI_062_S_1182_97164.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_0307_86179.nii  \n",
            "  inflating: data/MCI/wwmMCI_116_S_1271_101965.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0625_119028.nii  \n",
            "  inflating: data/MCI/wwmMCI_014_S_0658_73041.nii  \n",
            "  inflating: data/MCI/wwmMCI_041_S_1425_121404.nii  \n",
            "  inflating: data/MCI/wwmMCI_006_S_1130_73037.nii  \n",
            "  inflating: data/MCI/wwmMCI_053_S_0507_119157.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0994_91224.nii  \n",
            "  inflating: data/MCI/wwmMCI_041_S_1260_97125.nii  \n",
            "  inflating: data/MCI/wwmMCI_033_S_0513_119122.nii  \n",
            "  inflating: data/MCI/wwmMCI_036_S_0656_71536.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0668_81479.nii  \n",
            "  inflating: data/MCI/wwmMCI_094_S_0921_80397.nii  \n",
            "  inflating: data/MCI/wwmMCI_010_S_0422_118710.nii  \n",
            "  inflating: data/MCI/wwmMCI_035_S_0997_91659.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0481_89103.nii  \n",
            "  inflating: data/MCI/wwmMCI_014_S_0563_75300.nii  \n",
            "  inflating: data/MCI/wwmMCI_007_S_0293_118690.nii  \n",
            "  inflating: data/MCI/wwmMCI_129_S_1246_104531.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0800_79092.nii  \n",
            "  inflating: data/MCI/wwmMCI_116_S_1315_102120.nii  \n",
            "  inflating: data/MCI/wwmMCI_036_S_0673_71549.nii  \n",
            "  inflating: data/MCI/wwmMCI_021_S_0141_67941.nii  \n",
            "  inflating: data/MCI/wwmMCI_052_S_1346_105360.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_0116_119068.nii  \n",
            "  inflating: data/MCI/wwmMCI_007_S_0041_118697.nii  \n",
            "  inflating: data/MCI/wwmMCI_136_S_0107_119710.nii  \n",
            "  inflating: data/MCI/wwmMCI_041_S_1010_90566.nii  \n",
            "  inflating: data/MCI/wwmMCI_052_S_0952_119139.nii  \n",
            "  inflating: data/MCI/wwmMCI_053_S_0919_119174.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0030_118795.nii  \n",
            "  inflating: data/MCI/wwmMCI_116_S_0649_74411.nii  \n",
            "  inflating: data/MCI/wwmMCI_131_S_0384_80769.nii  \n",
            "  inflating: data/MCI/wwmMCI_003_S_1122_96010.nii  \n",
            "  inflating: data/MCI/wwmMCI_053_S_0621_119168.nii  \n",
            "  inflating: data/MCI/wwmMCI_016_S_1326_103313.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_1045_83453.nii  \n",
            "  inflating: data/MCI/wwmMCI_126_S_0708_72882.nii  \n",
            "  inflating: data/MCI/wwmMCI_011_S_1080_94387.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0887_118988.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0331_119003.nii  \n",
            "  inflating: data/MCI/wwmMCI_007_S_0698_119030.nii  \n",
            "  inflating: data/MCI/wwmMCI_116_S_0752_86132.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_0179_119071.nii  \n",
            "  inflating: data/MCI/wwmMCI_062_S_1299_101728.nii  \n",
            "  inflating: data/MCI/wwmMCI_022_S_1394_108348.nii  \n",
            "  inflating: data/MCI/wwmMCI_036_S_0869_88531.nii  \n",
            "  inflating: data/MCI/wwmMCI_099_S_1034_87166.nii  \n",
            "  inflating: data/MCI/wwmMCI_002_S_0729_78654.nii  \n",
            "  inflating: data/MCI/wwmMCI_051_S_1131_91824.nii  \n",
            "  inflating: data/MCI/wwmMCI_098_S_0269_89486.nii  \n",
            "  inflating: data/MCI/wwmMCI_098_S_0160_89459.nii  \n",
            "  inflating: data/MCI/wwmMCI_114_S_1106_92696.nii  \n",
            "  inflating: data/MCI/wwmMCI_127_S_1032_73218.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0042_118850.nii  \n",
            "  inflating: data/MCI/wwmMCI_021_S_0273_68448.nii  \n",
            "  inflating: data/MCI/wwmMCI_002_S_0782_118669.nii  \n",
            "  inflating: data/MCI/wwmMCI_014_S_0557_69569.nii  \n",
            "  inflating: data/MCI/wwmMCI_094_S_0434_65730.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0158_66199.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_0256_65999.nii  \n",
            "  inflating: data/MCI/wwmMCI_099_S_0551_65469.nii  \n",
            "  inflating: data/MCI/wwmMCI_037_S_0566_79813.nii  \n",
            "  inflating: data/MCI/wwmMCI_022_S_0961_83003.nii  \n",
            "  inflating: data/MCI/wwmMCI_041_S_1418_121653.nii  \n",
            "  inflating: data/MCI/wwmMCI_021_S_0276_67986.nii  \n",
            "  inflating: data/MCI/wwmMCI_002_S_1070_86304.nii  \n",
            "  inflating: data/MCI/wwmMCI_127_S_0112_97223.nii  \n",
            "  inflating: data/MCI/wwmMCI_057_S_0839_80230.nii  \n",
            "  inflating: data/MCI/wwmMCI_057_S_1269_96150.nii  \n",
            "  inflating: data/MCI/wwmMCI_033_S_0514_66544.nii  \n",
            "  inflating: data/MCI/wwmMCI_011_S_0241_66950.nii  \n",
            "  inflating: data/MCI/wwmMCI_126_S_0865_85636.nii  \n",
            "  inflating: data/MCI/wwmMCI_131_S_1389_105791.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0217_118999.nii  \n",
            "  inflating: data/MCI/wwmMCI_041_S_0314_65152.nii  \n",
            "  inflating: data/MCI/wwmMCI_021_S_0424_86050.nii  \n",
            "  inflating: data/MCI/wwmMCI_029_S_1384_103285.nii  \n",
            "  inflating: data/MCI/wwmMCI_023_S_0126_118973.nii  \n",
            "  inflating: data/MCI/wwmMCI_098_S_0667_89495.nii  \n",
            "  inflating: data/MCI/wwmMCI_007_S_0249_118989.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0631_66230.nii  \n",
            "  inflating: data/MCI/wwmMCI_002_S_1155_91395.nii  \n",
            "  inflating: data/MCI/wwmMCI_127_S_0925_85641.nii  \n",
            "  inflating: data/MCI/wwmMCI_099_S_0291_65442.nii  \n",
            "  inflating: data/MCI/wwmMCI_116_S_0361_64383.nii  \n",
            "  inflating: data/MCI/wwmMCI_033_S_0723_119127.nii  \n",
            "  inflating: data/MCI/wwmMCI_057_S_0464_72414.nii  \n",
            "  inflating: data/MCI/wwmMCI_029_S_1073_94872.nii  \n",
            "  inflating: data/MCI/wwmMCI_022_S_1351_97046.nii  \n",
            "  inflating: data/MCI/wwmMCI_123_S_0108_119311.nii  \n",
            "  inflating: data/MCI/wwmMCI_011_S_0362_89404.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0973_86013.nii  \n",
            "  inflating: data/MCI/wwmMCI_021_S_0626_73903.nii  \n",
            "  inflating: data/MCI/wwmMCI_057_S_1217_94588.nii  \n",
            "  inflating: data/MCI/wwmMCI_035_S_0292_39583.nii  \n",
            "  inflating: data/MCI/wwmMCI_114_S_0378_99104.nii  \n",
            "  inflating: data/MCI/wwmMCI_099_S_0051_47889.nii  \n",
            "  inflating: data/MCI/wwmMCI_137_S_0722_79085.nii  \n",
            "  inflating: data/MCI/wwmMCI_041_S_0679_74321.nii  \n",
            "  inflating: data/MCI/wwmMCI_127_S_0394_79391.nii  \n",
            "  inflating: data/MCI/wwmMCI_036_S_0945_95633.nii  \n",
            "  inflating: data/MCI/wwmMCI_016_S_1121_96234.nii  \n",
            "  inflating: data/MCI/wwmMCI_114_S_1118_98829.nii  \n",
            "  inflating: data/MCI/wwmMCI_027_S_0835_78885.nii  \n",
            "  inflating: data/MCI/wwmMCI_011_S_1282_94397.nii  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHbpYgMAKhj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "import skimage\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "class CustomResize(object):\n",
        "    def __init__(self, network_type, trg_size):\n",
        "\n",
        "        self.trg_size = trg_size\n",
        "        self.network_type = network_type\n",
        "\n",
        "    def __call__(self, img):\n",
        "        resized_img = self.resize_image(img, self.trg_size)\n",
        "        return resized_img\n",
        "\n",
        "    def resize_image(self, img, trg_size):\n",
        "        img_array = np.asarray(img.get_data())\n",
        "        res = resize(img_array, trg_size, mode='reflect', anti_aliasing=False, preserve_range=True)\n",
        "\n",
        "        # type check\n",
        "        if type(res) != np.ndarray:\n",
        "            raise \"type error!\"\n",
        "\n",
        "        # PIL image cannot handle 3D image, only return ndarray type, which ToTensor accepts\n",
        "        return res\n",
        "\n",
        "class CustomToTensor(object):\n",
        "    def __init__(self, network_type):\n",
        "\n",
        "        self.network_type = network_type\n",
        "\n",
        "    def __call__(self, pic):\n",
        "\n",
        "        if isinstance(pic, np.ndarray):\n",
        "            \n",
        "            img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
        "            \n",
        "            # backward compatibility\n",
        "            return img.float().div(255)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayhrjJtoLaJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class AD_Standard_CNN_Dataset(Dataset):\n",
        "    \"\"\"labeled Faces in the Wild dataset.\"\"\"\n",
        "    \n",
        "    def __init__(self, root_dir, data_file, transform=None, noise=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory of all the images.\n",
        "            data_file (string): File name of the train/test split file.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            data_augmentation (boolean): Optional data augmentation.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.data_file = data_file\n",
        "        self.transform = transform\n",
        "        self.noise = noise\n",
        "    \n",
        "    def __len__(self):\n",
        "\n",
        "        return sum(1 for line in open(self.data_file))\n",
        "    def __getitem__(self, idx):\n",
        "        df = open(self.data_file)\n",
        "        lines = df.readlines()\n",
        "        lst = lines[idx].split()\n",
        "        img_name = lst[0]\n",
        "        img_label = lst[1]\n",
        "        image_path = os.path.join(self.root_dir,img_label, img_name)\n",
        "        image = nib.load(image_path)\n",
        "        label=0\n",
        "        if img_label == 'Normal':\n",
        "            label = 0\n",
        "        elif img_label == 'AD':\n",
        "            label = 1\n",
        "        elif img_label == 'MCI':\n",
        "            label = 2\n",
        "        \n",
        "        image_array = np.array(image.get_data())\n",
        "        if self.noise:\n",
        "            image_array = gaussianNoise(image_array)\n",
        "        image_array = customToTensor(image_array)\n",
        "        sample = {'image': image_array, 'label': label}\n",
        "        \n",
        "        return sample\n",
        "\n",
        "def customToTensor(pic):\n",
        "    if isinstance(pic, np.ndarray):\n",
        "        img = torch.from_numpy(pic)\n",
        "        img = torch.unsqueeze(img,0)\n",
        "        # backward compatibility\n",
        "        return img.float()\n",
        "\n",
        "def gaussianNoise(img_array):\n",
        "    var_lst = [0, 0.0005, 0.00075, 0.001, 0.0025, 0.005]\n",
        "    w,h,d= img_array.shape\n",
        "    mean = 0\n",
        "    var = random.choice(var_lst)\n",
        "    sigma = var**0.5\n",
        "    gauss_noise = np.random.normal(mean,sigma,(w,h,d))\n",
        "    gauss_noise = gauss_noise.reshape(w,h,d)\n",
        "    noise_image = img_array + gauss_noise\n",
        "    return noise_image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wIr2gcBMVs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 410, kernel_size=7, stride=7, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=7,stride=7)\n",
        "        # self.conv2 = nn.Conv3d(410, 200, kernel_size=3, stride=1, padding=1)\n",
        "        # self.relu2 = nn.ReLU(inplace=True)\n",
        "        # self.pool2 = nn.MaxPool3d(kernel_size=3, stride=3)\n",
        "        # self.fc1 = nn.Linear(5*5*5*200, 800)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        #self.fc1 = nn.Linear(2*3*2*410, 80)\n",
        "        self.fc1 = nn.Linear(2*410, 80)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(80, num_classes)\n",
        "        self.softmax = nn.LogSoftmax()\n",
        "        self.parameter_initialization()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, out):\n",
        "        out = self.pool1(self.relu1(self.conv1(out)))\n",
        "        out = self.dropout1(out)\n",
        "        # out = self.pool2(self.relu2(self.conv2(out)))\n",
        "        # out = out.view(-1,5*5*5*200)\n",
        "        #print(out.shape)\n",
        "        #out = out.view(-1, 2*3*2*410)\n",
        "        out = out.view(-1, 2*410)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "        out = self.dropout2(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        out = self.softmax(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def parameter_initialization(self):\n",
        "        stdv = 1.0 / math.sqrt(410)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv_Znn-GMqkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8f8cc03-0a56-4828-c31e-d230ab7ce327"
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import cuda\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s %(levelname)s: %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S', level=logging.INFO)\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Starter code for CNN .\")\n",
        "\n",
        "parser.add_argument(\"--epochs\", default=20, type=int,\n",
        "                    help=\"Epochs through the data. (default=20)\")  \n",
        "parser.add_argument(\"--learning_rate\", \"-lr\", default=1e-3, type=float,\n",
        "                    help=\"Learning rate of the optimization. (default=0.01)\")\n",
        "parser.add_argument('--weight_decay', '--wd', default=1e-4, type=float,\n",
        "                    metavar='W', help='weight decay (default: 1e-4)')         \n",
        "parser.add_argument(\"--batch_size\", default=2, type=int,\n",
        "                    help=\"Batch size for training. (default=1)\")\n",
        "parser.add_argument(\"--gpuid\", default=[0], nargs='+', type=int,\n",
        "                    help=\"ID of gpu device to use. Empty implies cpu usage.\")\n",
        "parser.add_argument(\"--autoencoder\", default=False, type=bool,\n",
        "                    help=\"Whether to use the parameters from pretrained autoencoder.\")\n",
        "parser.add_argument(\"--num_classes\", default=3, type=int,\n",
        "                    help=\"The number of classes, 2 or 3.\")\n",
        "parser.add_argument(\"--estop\", default=1e-5, type=float,\n",
        "                    help=\"Early stopping criteria on the development set. (default=1e-2)\")  \n",
        "parser.add_argument(\"--noise\", default=True, type=bool,\n",
        "                    help=\"Whether to add gaussian noise to scans.\")\n",
        "# feel free to add more arguments as you need\n",
        "\n",
        "\n",
        "\n",
        "def main(options):\n",
        "    # Path configuration\n",
        "    if options.num_classes == 2:\n",
        "        TRAINING_PATH = 'train.txt'\n",
        "        TESTING_PATH = 'validation_2C_new.txt'\n",
        "    else:\n",
        "        TRAINING_PATH = 'label.txt'\n",
        "        TESTING_PATH = 'test.txt'\n",
        "    IMG_PATH = './data'\n",
        "\n",
        "    trg_size = (121, 145, 121)\n",
        "    \n",
        "    # transformations = transforms.Compose([CustomResize(\"CNN\", trg_size),\n",
        "    #                                       CustomToTensor(\"CNN\")\n",
        "    #                                     ])\n",
        "\n",
        "    dset_train = AD_Standard_CNN_Dataset(IMG_PATH, TRAINING_PATH, noise=True)\n",
        "    dset_test = AD_Standard_CNN_Dataset(IMG_PATH, TESTING_PATH, noise=False)\n",
        "\n",
        "    # Use argument load to distinguish training and testing\n",
        "\n",
        "    train_loader = DataLoader(dset_train,\n",
        "                              batch_size = options.batch_size,\n",
        "                              shuffle = True,\n",
        "                              num_workers = 4,\n",
        "                              drop_last = True\n",
        "                              )\n",
        "\n",
        "    test_loader = DataLoader(dset_test,\n",
        "                             batch_size = options.batch_size,\n",
        "                             shuffle = False,\n",
        "                             num_workers = 4,\n",
        "                             drop_last=True\n",
        "                             )\n",
        "\n",
        "    use_cuda = (len(options.gpuid) >= 1)\n",
        "    # if options.gpuid:\n",
        "    #     cuda.set_device(options.gpuid[0])\n",
        "\n",
        "    # Training process\n",
        "    model = CNN(options.num_classes)\n",
        "\n",
        "    if use_cuda > 0:\n",
        "        model = model.cuda()\n",
        "    else:\n",
        "        model.cpu()\n",
        "\n",
        "    if options.autoencoder:\n",
        "        pretrained_ae = torch.load(\"./autoencoder_pretrained_model39\")\n",
        "        model.state_dict()['conv1.weight'] = pretrained_ae['encoder.weight'].view(410,1,7,7,7)\n",
        "        model.state_dict()['conv1.bias'] = pretrained_ae['encoder.bias']\n",
        "\n",
        "        for p in model.conv1.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "\n",
        "    lr = options.learning_rate\n",
        "    optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, model.parameters()), lr, weight_decay=options.weight_decay)\n",
        "\n",
        "    # main training loop\n",
        "    last_dev_loss = 1e-4\n",
        "    max_acc = 0\n",
        "    max_epoch = 0\n",
        "    f1 = open(\"cnn_autoencoder_loss_train.txt\", 'a')\n",
        "    f2 = open(\"cnn_autoencoder_loss_dev.txt\", 'a')\n",
        "    for epoch_i in range(options.epochs):\n",
        "        logging.info(\"At {0}-th epoch.\".format(epoch_i))\n",
        "        train_loss = 0.0\n",
        "        correct_cnt = 0.0\n",
        "\n",
        "        for it, train_data in enumerate(train_loader):\n",
        "            data_dic = train_data\n",
        "\n",
        "            if use_cuda:\n",
        "                imgs, labels = Variable(data_dic['image']).cuda(), Variable(data_dic['label']).cuda() \n",
        "            else:\n",
        "                imgs, labels = Variable(data_dic['image']), Variable(data_dic['label'])\n",
        "\n",
        "            # add channel dimension: (batch_size, D, H ,W) to (batch_size, 1, D, H ,W)\n",
        "            # since 3D convolution requires 5D tensors\n",
        "            img_input = imgs#.unsqueeze(1)\n",
        "            #print(img_input.shape,labels.shape)\n",
        "            integer_encoded = labels.data.cpu().numpy()\n",
        "\n",
        "            # target should be LongTensor in loss function\n",
        "            ground_truth = Variable(torch.from_numpy(integer_encoded)).long()\n",
        "            if use_cuda:\n",
        "                ground_truth = ground_truth.cuda()\n",
        "                \n",
        "            train_output = model(img_input)\n",
        "\n",
        "            train_prob_predict = F.softmax(train_output, dim=1)\n",
        "            _, predict = train_prob_predict.topk(1)\n",
        "            #print(ground_truth.shape,predict.shape)\n",
        "            loss = criterion(train_output, ground_truth)\n",
        "\n",
        "            train_loss += loss\n",
        "            correct_this_batch = (predict.squeeze(1) == ground_truth).sum().float()\n",
        "            correct_cnt += correct_this_batch\n",
        "            accuracy = float(correct_this_batch) / len(ground_truth)\n",
        "            #logging.info(\"batch {0} training loss is : {1:.5f}\".format(it, loss.data))\n",
        "            #logging.info(\"batch {0} training accuracy is : {1:.5f}\".format(it, accuracy))\n",
        "            f1.write(\"batch {0} training loss is : {1:.5f}\\n\".format(it, loss.data))\n",
        "            f1.write(\"batch {0} training accuracy is : {1:.5f}\\n\".format(it, loss.data))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_avg_loss = train_loss / (len(dset_train) / options.batch_size)\n",
        "        train_avg_acu = float(correct_cnt) / len(dset_train)\n",
        "        logging.info(\"Average training loss is {0:.5f} at the end of epoch {1}\".format(train_avg_loss.data, epoch_i))\n",
        "        logging.info(\"Average training accuracy is {0:.5f} at the end of epoch {1}\".format(train_avg_acu, epoch_i))\n",
        "        \n",
        "        # validation -- this is a crude esitmation because there might be some paddings at the end\n",
        "        dev_loss = 0.0\n",
        "        correct_cnt = 0.0\n",
        "        model.eval()\n",
        "        for it, test_data in enumerate(test_loader):\n",
        "            data_dic = test_data\n",
        "\n",
        "            if use_cuda:\n",
        "                imgs, labels = Variable(data_dic['image'], volatile=True).cuda(), Variable(data_dic['label'], volatile=True).cuda() \n",
        "            else:\n",
        "                imgs, labels = Variable(data_dic['image'], volatile=True), Variable(data_dic['label'], volatile=True)\n",
        "\n",
        "            img_input = imgs#.unsqueeze(1)\n",
        "            integer_encoded = labels.data.cpu().numpy()\n",
        "            ground_truth = Variable(torch.from_numpy(integer_encoded), volatile=True).long()\n",
        "            if use_cuda:\n",
        "                ground_truth = ground_truth.cuda()\n",
        "            test_output = model(img_input)\n",
        "            test_prob_predict = F.softmax(test_output, dim=1)\n",
        "            _, predict = test_prob_predict.topk(1)\n",
        "            loss = criterion(test_output, ground_truth)\n",
        "            dev_loss += loss\n",
        "            correct_this_batch = (predict.squeeze(1) == ground_truth).sum().float()\n",
        "            correct_cnt += (predict.squeeze(1) == ground_truth).sum()\n",
        "            accuracy = float(correct_this_batch) / len(ground_truth)\n",
        "            #logging.info(\"batch {0} dev loss is : {1:.5f}\".format(it, loss.data))\n",
        "            #logging.info(\"batch {0} dev accuracy is : {1:.5f}\".format(it, accuracy))\n",
        "            f2.write(\"batch {0} dev loss is : {1:.5f}\\n\".format(it, loss.data))\n",
        "            f2.write(\"batch {0} dev accuracy is : {1:.5f}\\n\".format(it, accuracy))\n",
        "\n",
        "        dev_avg_loss = dev_loss / (len(dset_test) / options.batch_size)\n",
        "        dev_avg_acu = float(correct_cnt) / len(dset_test)\n",
        "        logging.info(\"Average validation loss is {0:.5f} at the end of epoch {1}\".format(dev_avg_loss.data, epoch_i))\n",
        "        logging.info(\"Average validation accuracy is {0:.5f} at the end of epoch {1}\".format(dev_avg_acu, epoch_i))\n",
        "\n",
        "        if dev_avg_acu > max_acc:\n",
        "            max_acc = dev_avg_acu\n",
        "            max_epoch = epoch_i\n",
        "\n",
        "        #if (abs(dev_avg_loss.data[0] - last_dev_loss) <= options.estop) or ((epoch_i+1)%20==0):\n",
        "        if max_acc>=0.75:\n",
        "            torch.save(model.state_dict(), open(\"3DCNN_model_\" + str(epoch_i) + '_' + str(max_acc), 'wb'))\n",
        "        last_dev_loss = dev_avg_loss.data\n",
        "        logging.info(\"Maximum accuracy on dev set is {0:.5f} for now\".format(max_acc))\n",
        "    logging.info(\"Maximum accuracy on dev set is {0:.5f} at the end of epoch {1}\".format(max_acc, max_epoch))\n",
        "    f1.close()\n",
        "    f2.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  ret = parser.parse_known_args()\n",
        "  options = ret[0]\n",
        "  if ret[1]:\n",
        "    logging.warning(\"unknown arguments: {0}\".format(parser.parse_known_args()[1]))\n",
        "  main(options)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-01 04:30:11 WARNING: unknown arguments: ['-f', '/root/.local/share/jupyter/runtime/kernel-6bbd7193-29c6-4103-9fd3-957359bc5ef9.json']\n",
            "2020-08-01 04:30:11 INFO: At 0-th epoch.\n",
            "2020-08-01 04:30:21 INFO: Average training loss is 1.15271 at the end of epoch 0\n",
            "2020-08-01 04:30:21 INFO: Average training accuracy is 0.36911 at the end of epoch 0\n",
            "2020-08-01 04:30:21 INFO: Average validation loss is 1.10624 at the end of epoch 0\n",
            "2020-08-01 04:30:21 INFO: Average validation accuracy is 0.36000 at the end of epoch 0\n",
            "2020-08-01 04:30:21 INFO: Maximum accuracy on dev set is 0.36000 for now\n",
            "2020-08-01 04:30:21 INFO: At 1-th epoch.\n",
            "2020-08-01 04:30:31 INFO: Average training loss is 1.09397 at the end of epoch 1\n",
            "2020-08-01 04:30:31 INFO: Average training accuracy is 0.34555 at the end of epoch 1\n",
            "2020-08-01 04:30:32 INFO: Average validation loss is 1.11000 at the end of epoch 1\n",
            "2020-08-01 04:30:32 INFO: Average validation accuracy is 0.36000 at the end of epoch 1\n",
            "2020-08-01 04:30:32 INFO: Maximum accuracy on dev set is 0.36000 for now\n",
            "2020-08-01 04:30:32 INFO: At 2-th epoch.\n",
            "2020-08-01 04:30:42 INFO: Average training loss is 1.09028 at the end of epoch 2\n",
            "2020-08-01 04:30:42 INFO: Average training accuracy is 0.39791 at the end of epoch 2\n",
            "2020-08-01 04:30:43 INFO: Average validation loss is 1.09339 at the end of epoch 2\n",
            "2020-08-01 04:30:43 INFO: Average validation accuracy is 0.36000 at the end of epoch 2\n",
            "2020-08-01 04:30:43 INFO: Maximum accuracy on dev set is 0.36000 for now\n",
            "2020-08-01 04:30:43 INFO: At 3-th epoch.\n",
            "2020-08-01 04:30:53 INFO: Average training loss is 1.08714 at the end of epoch 3\n",
            "2020-08-01 04:30:53 INFO: Average training accuracy is 0.36387 at the end of epoch 3\n",
            "2020-08-01 04:30:53 INFO: Average validation loss is 1.09527 at the end of epoch 3\n",
            "2020-08-01 04:30:53 INFO: Average validation accuracy is 0.36000 at the end of epoch 3\n",
            "2020-08-01 04:30:53 INFO: Maximum accuracy on dev set is 0.36000 for now\n",
            "2020-08-01 04:30:53 INFO: At 4-th epoch.\n",
            "2020-08-01 04:31:03 INFO: Average training loss is 1.08734 at the end of epoch 4\n",
            "2020-08-01 04:31:03 INFO: Average training accuracy is 0.37958 at the end of epoch 4\n",
            "2020-08-01 04:31:04 INFO: Average validation loss is 1.08482 at the end of epoch 4\n",
            "2020-08-01 04:31:04 INFO: Average validation accuracy is 0.36000 at the end of epoch 4\n",
            "2020-08-01 04:31:04 INFO: Maximum accuracy on dev set is 0.36000 for now\n",
            "2020-08-01 04:31:04 INFO: At 5-th epoch.\n",
            "2020-08-01 04:31:14 INFO: Average training loss is 1.08282 at the end of epoch 5\n",
            "2020-08-01 04:31:14 INFO: Average training accuracy is 0.40838 at the end of epoch 5\n",
            "2020-08-01 04:31:14 INFO: Average validation loss is 1.08190 at the end of epoch 5\n",
            "2020-08-01 04:31:14 INFO: Average validation accuracy is 0.38000 at the end of epoch 5\n",
            "2020-08-01 04:31:14 INFO: Maximum accuracy on dev set is 0.38000 for now\n",
            "2020-08-01 04:31:14 INFO: At 6-th epoch.\n",
            "2020-08-01 04:31:24 INFO: Average training loss is 1.07107 at the end of epoch 6\n",
            "2020-08-01 04:31:24 INFO: Average training accuracy is 0.43979 at the end of epoch 6\n",
            "2020-08-01 04:31:25 INFO: Average validation loss is 1.06622 at the end of epoch 6\n",
            "2020-08-01 04:31:25 INFO: Average validation accuracy is 0.40000 at the end of epoch 6\n",
            "2020-08-01 04:31:25 INFO: Maximum accuracy on dev set is 0.40000 for now\n",
            "2020-08-01 04:31:25 INFO: At 7-th epoch.\n",
            "2020-08-01 04:31:35 INFO: Average training loss is 1.06629 at the end of epoch 7\n",
            "2020-08-01 04:31:35 INFO: Average training accuracy is 0.43979 at the end of epoch 7\n",
            "2020-08-01 04:31:36 INFO: Average validation loss is 1.02950 at the end of epoch 7\n",
            "2020-08-01 04:31:36 INFO: Average validation accuracy is 0.40000 at the end of epoch 7\n",
            "2020-08-01 04:31:36 INFO: Maximum accuracy on dev set is 0.40000 for now\n",
            "2020-08-01 04:31:36 INFO: At 8-th epoch.\n",
            "2020-08-01 04:31:46 INFO: Average training loss is 1.03366 at the end of epoch 8\n",
            "2020-08-01 04:31:46 INFO: Average training accuracy is 0.42932 at the end of epoch 8\n",
            "2020-08-01 04:31:46 INFO: Average validation loss is 1.00443 at the end of epoch 8\n",
            "2020-08-01 04:31:46 INFO: Average validation accuracy is 0.46000 at the end of epoch 8\n",
            "2020-08-01 04:31:46 INFO: Maximum accuracy on dev set is 0.46000 for now\n",
            "2020-08-01 04:31:46 INFO: At 9-th epoch.\n",
            "2020-08-01 04:31:56 INFO: Average training loss is 1.01790 at the end of epoch 9\n",
            "2020-08-01 04:31:56 INFO: Average training accuracy is 0.45026 at the end of epoch 9\n",
            "2020-08-01 04:31:57 INFO: Average validation loss is 1.01104 at the end of epoch 9\n",
            "2020-08-01 04:31:57 INFO: Average validation accuracy is 0.42000 at the end of epoch 9\n",
            "2020-08-01 04:31:57 INFO: Maximum accuracy on dev set is 0.46000 for now\n",
            "2020-08-01 04:31:57 INFO: At 10-th epoch.\n",
            "2020-08-01 04:32:07 INFO: Average training loss is 1.00685 at the end of epoch 10\n",
            "2020-08-01 04:32:07 INFO: Average training accuracy is 0.48168 at the end of epoch 10\n",
            "2020-08-01 04:32:07 INFO: Average validation loss is 0.88701 at the end of epoch 10\n",
            "2020-08-01 04:32:07 INFO: Average validation accuracy is 0.64000 at the end of epoch 10\n",
            "2020-08-01 04:32:07 INFO: Maximum accuracy on dev set is 0.64000 for now\n",
            "2020-08-01 04:32:07 INFO: At 11-th epoch.\n",
            "2020-08-01 04:32:17 INFO: Average training loss is 0.97292 at the end of epoch 11\n",
            "2020-08-01 04:32:17 INFO: Average training accuracy is 0.51309 at the end of epoch 11\n",
            "2020-08-01 04:32:18 INFO: Average validation loss is 0.93652 at the end of epoch 11\n",
            "2020-08-01 04:32:18 INFO: Average validation accuracy is 0.52000 at the end of epoch 11\n",
            "2020-08-01 04:32:18 INFO: Maximum accuracy on dev set is 0.64000 for now\n",
            "2020-08-01 04:32:18 INFO: At 12-th epoch.\n",
            "2020-08-01 04:32:28 INFO: Average training loss is 0.95042 at the end of epoch 12\n",
            "2020-08-01 04:32:28 INFO: Average training accuracy is 0.52618 at the end of epoch 12\n",
            "2020-08-01 04:32:28 INFO: Average validation loss is 0.83672 at the end of epoch 12\n",
            "2020-08-01 04:32:28 INFO: Average validation accuracy is 0.60000 at the end of epoch 12\n",
            "2020-08-01 04:32:28 INFO: Maximum accuracy on dev set is 0.64000 for now\n",
            "2020-08-01 04:32:28 INFO: At 13-th epoch.\n",
            "2020-08-01 04:32:38 INFO: Average training loss is 0.91513 at the end of epoch 13\n",
            "2020-08-01 04:32:38 INFO: Average training accuracy is 0.54450 at the end of epoch 13\n",
            "2020-08-01 04:32:39 INFO: Average validation loss is 0.82725 at the end of epoch 13\n",
            "2020-08-01 04:32:39 INFO: Average validation accuracy is 0.64000 at the end of epoch 13\n",
            "2020-08-01 04:32:39 INFO: Maximum accuracy on dev set is 0.64000 for now\n",
            "2020-08-01 04:32:39 INFO: At 14-th epoch.\n",
            "2020-08-01 04:32:49 INFO: Average training loss is 0.85809 at the end of epoch 14\n",
            "2020-08-01 04:32:49 INFO: Average training accuracy is 0.59686 at the end of epoch 14\n",
            "2020-08-01 04:32:50 INFO: Average validation loss is 0.93297 at the end of epoch 14\n",
            "2020-08-01 04:32:50 INFO: Average validation accuracy is 0.56000 at the end of epoch 14\n",
            "2020-08-01 04:32:50 INFO: Maximum accuracy on dev set is 0.64000 for now\n",
            "2020-08-01 04:32:50 INFO: At 15-th epoch.\n",
            "2020-08-01 04:33:00 INFO: Average training loss is 0.85276 at the end of epoch 15\n",
            "2020-08-01 04:33:00 INFO: Average training accuracy is 0.55236 at the end of epoch 15\n",
            "2020-08-01 04:33:00 INFO: Average validation loss is 0.71141 at the end of epoch 15\n",
            "2020-08-01 04:33:00 INFO: Average validation accuracy is 0.74000 at the end of epoch 15\n",
            "2020-08-01 04:33:00 INFO: Maximum accuracy on dev set is 0.74000 for now\n",
            "2020-08-01 04:33:00 INFO: At 16-th epoch.\n",
            "2020-08-01 04:33:10 INFO: Average training loss is 0.78224 at the end of epoch 16\n",
            "2020-08-01 04:33:10 INFO: Average training accuracy is 0.65969 at the end of epoch 16\n",
            "2020-08-01 04:33:11 INFO: Average validation loss is 0.68728 at the end of epoch 16\n",
            "2020-08-01 04:33:11 INFO: Average validation accuracy is 0.66000 at the end of epoch 16\n",
            "2020-08-01 04:33:11 INFO: Maximum accuracy on dev set is 0.74000 for now\n",
            "2020-08-01 04:33:11 INFO: At 17-th epoch.\n",
            "2020-08-01 04:33:21 INFO: Average training loss is 0.74058 at the end of epoch 17\n",
            "2020-08-01 04:33:21 INFO: Average training accuracy is 0.67539 at the end of epoch 17\n",
            "2020-08-01 04:33:21 INFO: Average validation loss is 0.65051 at the end of epoch 17\n",
            "2020-08-01 04:33:21 INFO: Average validation accuracy is 0.76000 at the end of epoch 17\n",
            "2020-08-01 04:33:21 INFO: Maximum accuracy on dev set is 0.76000 for now\n",
            "2020-08-01 04:33:22 INFO: At 18-th epoch.\n",
            "2020-08-01 04:33:32 INFO: Average training loss is 0.74099 at the end of epoch 18\n",
            "2020-08-01 04:33:32 INFO: Average training accuracy is 0.69372 at the end of epoch 18\n",
            "2020-08-01 04:33:32 INFO: Average validation loss is 0.62188 at the end of epoch 18\n",
            "2020-08-01 04:33:32 INFO: Average validation accuracy is 0.78000 at the end of epoch 18\n",
            "2020-08-01 04:33:32 INFO: Maximum accuracy on dev set is 0.78000 for now\n",
            "2020-08-01 04:33:32 INFO: At 19-th epoch.\n",
            "2020-08-01 04:33:43 INFO: Average training loss is 0.69084 at the end of epoch 19\n",
            "2020-08-01 04:33:43 INFO: Average training accuracy is 0.68325 at the end of epoch 19\n",
            "2020-08-01 04:33:43 INFO: Average validation loss is 0.55260 at the end of epoch 19\n",
            "2020-08-01 04:33:43 INFO: Average validation accuracy is 0.84000 at the end of epoch 19\n",
            "2020-08-01 04:33:43 INFO: Maximum accuracy on dev set is 0.84000 for now\n",
            "2020-08-01 04:33:43 INFO: Maximum accuracy on dev set is 0.84000 at the end of epoch 19\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDoYsScwg2kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "TRAINING_PATH_AD = 'data/AD'\n",
        "TRAINING_PATH_MCI = 'data/MCI'\n",
        "TRAINING_PATH_normal = 'data/normal'\n",
        "train=[TRAINING_PATH_AD,TRAINING_PATH_MCI,TRAINING_PATH_normal]\n",
        "f = open(\"label.txt\",'a')\n",
        "for train_data in train:\n",
        "\n",
        "\n",
        "    for img_name in os.listdir(train_data):\n",
        "\n",
        "        f.writelines([img_name,' ',train_data.split('/')[-1]])\n",
        "        f.write('\\n')\n",
        "with open('label.txt', 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()  # get all row\n",
        "    sum = 0\n",
        "    list = []\n",
        "    for line in lines:  # i-th row\n",
        "            # find first space \n",
        "        list.append(line)\n",
        "\n",
        "\n",
        "with open('test.txt', 'a', encoding='utf-8') as g:\n",
        "    a = random.sample(list, 50)  # sample 50 row randomly\n",
        "    for i in a:\n",
        "        g.write(i)\n",
        "    f.close()\n",
        "    g.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}